{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Import important libraries such as Tensorflow, Keras, Matlab plotting.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing libraries\nimport keras\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom IPython.display import display, Image # for displaying images\n%matplotlib inline\nimport os","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Find labels of images.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Getting labels of training data\nlabels = os.listdir('/kaggle/input/fruits-fresh-and-rotten-for-classification/dataset/dataset/train')\nlabels","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# STEP 2: Display Sample Images"},{"metadata":{"trusted":true},"cell_type":"code","source":"num = []\n\nfor i in labels:\n  path = '/kaggle/input/fruits-fresh-and-rotten-for-classification/dataset/dataset/train/{0}/'.format(i)\n  folder_data = os.listdir(path)\n  k=0\n  print('\\n', i.upper())\n  for j in folder_data:\n    if(k<2):\n      display(Image(path+j))\n    k=k+1\n  num.append(k)\n  print('there are ', k,' images in ', i, 'class')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Get images according to their class (banana, apple, orange).**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get images from files using ImageDataGenerator\n\nfrom keras.preprocessing.image import ImageDataGenerator\n\ndatagen = ImageDataGenerator(rescale=1./255,validation_split=0.2)\n\ntg = datagen.flow_from_directory(directory='/kaggle/input/fruits-fresh-and-rotten-for-classification/dataset/dataset/train', target_size=(224,224), classes=labels, batch_size=16, subset='training')\nvg = datagen.flow_from_directory(directory='/kaggle/input/fruits-fresh-and-rotten-for-classification/dataset/dataset/train', target_size=(224,224), classes=labels, batch_size=16, subset='validation')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# STEP 3: Build our Convolutional Neural Network"},{"metadata":{"trusted":true},"cell_type":"code","source":"# building model\nmodel = tf.keras.Sequential()\nmodel.add(tf.keras.layers.Conv2D(8, kernel_size=(5,5), activation='relu', input_shape = (224,224,3)))\nmodel.add(tf.keras.layers.MaxPool2D((2,2),strides=2))\n\nmodel.add(tf.keras.layers.Conv2D(16, kernel_size=(5,5), activation='relu'))\nmodel.add(tf.keras.layers.MaxPool2D((2,2),strides=2))\n\nmodel.add(tf.keras.layers.Conv2D(32, kernel_size=(7,7), activation='relu'))\nmodel.add(tf.keras.layers.MaxPool2D((2,2),strides=2))\n\nmodel.add(tf.keras.layers.Conv2D(64, kernel_size=(3,3), activation='relu'))\nmodel.add(tf.keras.layers.MaxPool2D((2,2),strides=2))\n\nmodel.add(tf.keras.layers.Conv2D(128, kernel_size=(3,3), activation='relu'))\nmodel.add(tf.keras.layers.MaxPool2D((2,2),strides=2))\n\nmodel.add(tf.keras.layers.Conv2D(256, kernel_size=(3,3), activation='relu'))\n\n\nmodel.add(tf.keras.layers.Flatten())\nmodel.add(tf.keras.layers.Dropout(0.5))\nmodel.add(tf.keras.layers.Dense(512, activation='relu'))\nmodel.add(tf.keras.layers.Dense(512, activation='relu'))\n\nmodel.add(tf.keras.layers.Dense(6, activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Compile model.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compile model\nopt = tf.keras.optimizers.Adam(learning_rate=0.0001)\nmodel.compile(optimizer=opt, loss = 'categorical_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Summary of our model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary(line_length=None, positions=None, print_fn=None)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Train our model.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train model\nhistory = model.fit_generator(generator=tg, steps_per_epoch=len(tg), epochs=25, validation_data=vg, validation_steps=len(vg))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# STEP 4: SHOW IMPORTANT PLOTS"},{"metadata":{},"cell_type":"markdown","source":"**Plot Accuracy over epochs plot. (Higher over time is better)**"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend(['Acc','Val'], loc = 'upper left')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Plot Loss over epochs plot. (Lower over time is better)**"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend(['loss','Val'], loc = 'upper left')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# STEP 5: Test our model"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_set = datagen.flow_from_directory(directory='/kaggle/input/fruits-fresh-and-rotten-for-classification/dataset/test', target_size=(224,224), classes=labels, batch_size=16, subset='validation')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction = model.predict(test_set)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}